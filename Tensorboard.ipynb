{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16cfa3da-c0b0-4a9b-a7b9-ccda8192f16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\root\\anaconda3\\envs\\torch-env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: <object object at 0x0000020D7B4AC930>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "%matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c77d20a-5794-44c1-969c-d5be3970a7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download training data from open datasets\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "#Download the test data from open datasets\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9bd2ac8-fbfb-4ef6-91e0-3e5358d15863",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "#Create data loaders\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = (\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img/2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    if one_channel: \n",
    "        plt.plot(npimg)\n",
    "    else:\n",
    "        ptl.imshow(np.transpose(npimage, (1,2,0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13e204e5-1d4a-4d5d-8ae4-2406d03cf95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Get cpu or gpu device for training\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "#Define model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,6,5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        self.fc1 = nn.Linear(16*4*4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = x.view(-1, 16*4*4)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = Net().to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93069df7-2c52-4c40-a025-a12d5ea42791",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2fd5b74-89f5-4579-9705-7842b60f7bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writter = SummaryWriter(\"runs/fashion_mnist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc60bc0-e282-4b4e-a5da-67b8aabe91ba",
   "metadata": {},
   "source": [
    "## Writing to Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff8c8423-5837-4e39-86bd-5a8fe37300bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get some random training images\n",
    "data_iter = iter(train_dataloader)\n",
    "images, labels = data_iter.next()\n",
    "\n",
    "#create grid of images\n",
    "img_grid = make_grid(images)\n",
    "\n",
    "#show images\n",
    "#matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "#write to tensorboard\n",
    "writter.add_image('four_fasion_mnist_images', img_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "486105fb-2a6b-46d0-bd11-4cba6fb76e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        #compute the prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        \n",
    "        #Backpropagtion\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "797e3cdf-2da0-4c5c-8406-f48ff84bcf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        test_loss /= size\n",
    "        correct /= size\n",
    "        print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54996631-4abc-48a1-b353-10953547cd80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f21507d-98f5-4f36-ac7f-960514970ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      " -------------------------------\n",
      "loss: 2.292957 [    0/60000]\n",
      "loss: 2.311231 [ 6400/60000]\n",
      "loss: 2.299067 [12800/60000]\n",
      "loss: 2.302268 [19200/60000]\n",
      "loss: 2.289737 [25600/60000]\n",
      "loss: 2.278692 [32000/60000]\n",
      "loss: 2.253475 [38400/60000]\n",
      "loss: 2.155120 [44800/60000]\n",
      "loss: 1.694135 [51200/60000]\n",
      "loss: 1.337099 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 0.017975 \n",
      "\n",
      "Epoch 2\n",
      " -------------------------------\n",
      "loss: 1.022878 [    0/60000]\n",
      "loss: 1.039346 [ 6400/60000]\n",
      "loss: 0.914827 [12800/60000]\n",
      "loss: 0.928122 [19200/60000]\n",
      "loss: 0.887062 [25600/60000]\n",
      "loss: 0.730862 [32000/60000]\n",
      "loss: 0.897100 [38400/60000]\n",
      "loss: 0.739965 [44800/60000]\n",
      "loss: 0.844458 [51200/60000]\n",
      "loss: 0.681556 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 0.012103 \n",
      "\n",
      "Epoch 3\n",
      " -------------------------------\n",
      "loss: 0.717838 [    0/60000]\n",
      "loss: 0.757296 [ 6400/60000]\n",
      "loss: 0.776201 [12800/60000]\n",
      "loss: 0.597284 [19200/60000]\n",
      "loss: 0.877646 [25600/60000]\n",
      "loss: 0.863646 [32000/60000]\n",
      "loss: 0.600088 [38400/60000]\n",
      "loss: 0.513683 [44800/60000]\n",
      "loss: 0.721436 [51200/60000]\n",
      "loss: 0.832019 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.1%, Avg loss: 0.010899 \n",
      "\n",
      "Epoch 4\n",
      " -------------------------------\n",
      "loss: 0.661098 [    0/60000]\n",
      "loss: 0.749623 [ 6400/60000]\n",
      "loss: 0.437058 [12800/60000]\n",
      "loss: 0.667156 [19200/60000]\n",
      "loss: 0.616969 [25600/60000]\n",
      "loss: 0.474431 [32000/60000]\n",
      "loss: 0.555034 [38400/60000]\n",
      "loss: 0.626123 [44800/60000]\n",
      "loss: 0.511708 [51200/60000]\n",
      "loss: 0.740751 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 0.009661 \n",
      "\n",
      "Epoch 5\n",
      " -------------------------------\n",
      "loss: 0.595106 [    0/60000]\n",
      "loss: 0.420049 [ 6400/60000]\n",
      "loss: 0.763341 [12800/60000]\n",
      "loss: 0.635315 [19200/60000]\n",
      "loss: 0.635670 [25600/60000]\n",
      "loss: 0.432273 [32000/60000]\n",
      "loss: 0.551175 [38400/60000]\n",
      "loss: 0.635051 [44800/60000]\n",
      "loss: 0.546892 [51200/60000]\n",
      "loss: 0.667148 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.009055 \n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n -------------------------------\")\n",
    "    train(train_dataloader, model, loss, optimizer)\n",
    "    test(test_dataloader, model)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "595ae3a2-52e1-462f-9808-29e486ff760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.to(device)\n",
    "writter.add_graph(model, images)\n",
    "writter.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3b870d5-796b-4bd1-93e0-84424732ff23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e48a634-a765-4e77-be18-787966552d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ad1002-9550-45e4-959c-7f6a85331682",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
